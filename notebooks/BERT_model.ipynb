{
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import warnings\n",
        "\n",
        "warnings.filterwarnings(\"ignore\")\n",
        "os.environ[\"TF_CPP_MIN_LOG_LEVEL\"] = \"2\"\n",
        "\n",
        "# Set `PATH` to include the directory containing saved_model_cli\n",
        "PATH = %env PATH\n",
        "%env PATH=/home/jupyter/.local/bin:{PATH}"
      ],
      "metadata": {
        "id": "3tFneshPHs3L",
        "outputId": "c828e7c4-dd1b-4808-a559-2ad02f4bd9af",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "id": "3tFneshPHs3L",
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "env: PATH=/home/jupyter/.local/bin:/home/jupyter/.local/bin:/opt/bin:/usr/local/nvidia/bin:/usr/local/cuda/bin:/usr/local/sbin:/usr/local/bin:/usr/sbin:/usr/bin:/sbin:/bin:/tools/node/bin:/tools/google-cloud-sdk/bin\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#!pip uninstall -y tensorflow tensorflow-text transformers"
      ],
      "metadata": {
        "id": "Au23_whUkmgD"
      },
      "id": "Au23_whUkmgD",
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#!pip install tensorflow==2.15.0 tensorflow_text==2.15.0 transformers==4.51.0"
      ],
      "metadata": {
        "collapsed": true,
        "id": "NVJo3nF6kp7N"
      },
      "id": "NVJo3nF6kp7N",
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import datetime\n",
        "import shutil\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "import tensorflow as tf\n",
        "import tensorflow_text as text\n",
        "\n",
        "#from official.nlp import optimization\n",
        "tf.get_logger().setLevel(\"ERROR\")"
      ],
      "metadata": {
        "id": "UJ7npcepJkkC"
      },
      "id": "UJ7npcepJkkC",
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!git clone https://github.com/eminedemirbas/Hackathon-YZTA"
      ],
      "metadata": {
        "id": "oMD4Qji_J0pO",
        "outputId": "b222f3ea-c414-440b-c40e-4109bc84c498",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "id": "oMD4Qji_J0pO",
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "fatal: destination path 'Hackathon-YZTA' already exists and is not an empty directory.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "repo_path = \"/content/Hackathon-YZTA\"\n",
        "\n",
        "\n",
        "data_path = os.path.join(repo_path, 'data')\n",
        "\n",
        "\n",
        "if os.path.exists(data_path):\n",
        "    print(f\"Data klasörü bulundu: {data_path}\")\n",
        "else:\n",
        "    print(\"Data klasörü bulunamadı.\")"
      ],
      "metadata": {
        "id": "VK-1CTDhKlG8",
        "outputId": "fca03762-a8f4-46ca-f84b-7c0d17a68d84",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "id": "VK-1CTDhKlG8",
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Data klasörü bulundu: /content/Hackathon-YZTA/data\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Veriyi yüklemek için klasör yolunu kullanacağız\n",
        "train_dir = os.path.join(data_path, 'train')\n",
        "test_dir = os.path.join(data_path, 'test')"
      ],
      "metadata": {
        "id": "k9nKM8ehMtB4"
      },
      "id": "k9nKM8ehMtB4",
      "execution_count": 21,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "AUTOTUNE = tf.data.AUTOTUNE\n",
        "batch_size = 32\n",
        "seed = 42\n",
        "\n",
        "raw_train_ds = tf.keras.preprocessing.text_dataset_from_directory(\n",
        "    train_dir,\n",
        "    batch_size=batch_size,\n",
        "    validation_split=0.2,\n",
        "    subset=\"training\",\n",
        "    seed=seed,\n",
        ")\n",
        "\n",
        "class_names = raw_train_ds.class_names\n",
        "train_ds = raw_train_ds.cache().prefetch(buffer_size=AUTOTUNE)\n",
        "\n",
        "val_ds = tf.keras.preprocessing.text_dataset_from_directory(\n",
        "    train_dir,\n",
        "    batch_size=batch_size,\n",
        "    validation_split=0.2,\n",
        "    subset=\"validation\",\n",
        "    seed=seed,\n",
        ")\n",
        "\n",
        "val_ds = val_ds.cache().prefetch(buffer_size=AUTOTUNE)\n",
        "\n",
        "test_ds = tf.keras.preprocessing.text_dataset_from_directory(\n",
        "    test_dir, batch_size=batch_size\n",
        ")\n",
        "\n",
        "test_ds = test_ds.cache().prefetch(buffer_size=AUTOTUNE)"
      ],
      "metadata": {
        "id": "LqTr6VzIM011",
        "outputId": "7d188060-65e5-4186-c323-ab80fc1d9deb",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "id": "LqTr6VzIM011",
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Found 3443 files belonging to 2 classes.\n",
            "Using 2755 files for training.\n",
            "Found 3443 files belonging to 2 classes.\n",
            "Using 688 files for validation.\n",
            "Found 1000 files belonging to 2 classes.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "for text_batch, label_batch in train_ds.take(1):\n",
        "    for i in range(3):\n",
        "        # Byte formatındaki veriyi UTF-8'e çevir\n",
        "        review_text = text_batch.numpy()[i].decode('utf-8')\n",
        "        print(f\"Review:  {review_text}\")\n",
        "        label = label_batch.numpy()[i]\n",
        "        print(f\"Label : {label} ({class_names[label]})\")"
      ],
      "metadata": {
        "id": "A8C8rvH0NLfJ",
        "outputId": "18c93237-000f-465c-e328-ff73ac2b1f40",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "id": "A8C8rvH0NLfJ",
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Review:  Kişi bugün evden işe giderken 35 km’lik mesafeyi özel aracıyla katederek 7.2 kg CO2 salımına neden oldu. Yolculuk boyunca araçta tek başınaydı. Gıda alışverişinde et ürünleri ve ithal meyveler alındı. Akşam yemeği hazır gıdalardan oluştu ve yoğun plastik ambalaj kullanımı vardı. Evdeki çamaşır makinesi düşük dolulukla çalıştırıldı. Isıtıcılar yüksek ayarda uzun süre çalıştı. Işıklar kullanılmayan odalarda da açık bırakıldı. Atıkların ayrıştırılması ihmal edildi. Gün boyunca yapılan bu tercihler toplamda 15 kg CO2 emisyonuna yol açtı. Bu davranışların doğaya etkisi ciddi düzeyde olumsuzdur.\n",
            "\n",
            "\n",
            "Label : 0 (neg)\n",
            "Review:  Sabah, kısa mesafeye arabayla gitmen çevreye büyük bir zarar verdi. Yolda yürümek veya bisiklet kullanmak, çevreyi korumak adına çok daha iyi bir seçenek olabilirdi. Öğle yemeğinde dışarıda ambalajlı yiyecekler tükettin, bu da doğaya zarar veren atıkların artmasına yol açtı. Akşam alışveriş için arabanı kullandın, gereksiz yakıt harcadın. Çamaşırları yüksek sıcaklıkta yıkadın ve cihazları gece boyunca açık bıraktın. Bugün, CO₂ salımın 40.5 kg oldu. Bu yüksek salımlar, çevreyi tehdit ediyor ve ekolojik dengenin korunması için daha bilinçli bir yaşam tarzı benimsemen gerektiğini gösteriyor.\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "Label : 0 (neg)\n",
            "Review:  Toprakta yetiştirilen organik ürünleri tüketmek, sentetik gübre ve ilaç kullanımını azaltır, bu da karbon ayak izini düşürür. Bilimsel araştırmalar, organik tarımın iklim üzerindeki olumlu etkilerini göstermektedir.\n",
            "Label : 1 (pos)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import transformers\n",
        "import keras\n",
        "\n",
        "print(\"Transformers sürümü:\", transformers.__version__)\n",
        "print(\"Keras sürümü:\", keras.__version__)\n"
      ],
      "metadata": {
        "id": "m6tNZQ19Tf_1",
        "outputId": "84382254-3f7e-4297-8ea1-75eff1142a02",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "id": "m6tNZQ19Tf_1",
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Transformers sürümü: 4.51.3\n",
            "Keras sürümü: 3.8.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from transformers import TFAutoModel, AutoTokenizer\n",
        "\n",
        "model_name = \"dbmdz/bert-base-turkish-uncased\"\n",
        "tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
        "bert_model = TFAutoModel.from_pretrained(model_name)"
      ],
      "metadata": {
        "collapsed": true,
        "id": "LXFgAMy5X11A",
        "outputId": "521b71c6-8495-4e77-d1b9-472faf891e89",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "id": "LXFgAMy5X11A",
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Some layers from the model checkpoint at dbmdz/bert-base-turkish-uncased were not used when initializing TFBertModel: ['nsp___cls', 'mlm___cls']\n",
            "- This IS expected if you are initializing TFBertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
            "- This IS NOT expected if you are initializing TFBertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
            "All the layers of TFBertModel were initialized from the model checkpoint at dbmdz/bert-base-turkish-uncased.\n",
            "If your task is similar to the task the model of the checkpoint was trained on, you can already use TFBertModel for predictions without further training.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "text_test = [\"Çevreye zarar verdin!\"]\n",
        "\n",
        "inputs = tokenizer(text_test, padding=True, truncation=True, return_tensors=\"tf\")\n",
        "\n",
        "print(f\"Keys       : {list(inputs.keys())}\")\n",
        "\n",
        "print(f\"Shape      : {inputs['input_ids'].shape}\")\n",
        "print(f\"Word Ids   : {inputs['input_ids'][0, :12]}\")\n",
        "\n",
        "print(f\"Attention Mask : {inputs['attention_mask'][0, :12]}\")"
      ],
      "metadata": {
        "id": "7Q8nx2WLahv7",
        "outputId": "9520eabd-a689-4f0d-f8bc-b274e591db8f",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "id": "7Q8nx2WLahv7",
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Keys       : ['input_ids', 'token_type_ids', 'attention_mask']\n",
            "Shape      : (1, 8)\n",
            "Word Ids   : [    2  3231 20834  1028  3840 19988     5     3]\n",
            "Attention Mask : [1 1 1 1 1 1 1 1]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "bert_results = bert_model(**inputs)"
      ],
      "metadata": {
        "id": "VjKekclRdjLu"
      },
      "id": "VjKekclRdjLu",
      "execution_count": 27,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(f\"Loaded BERT model : {bert_model}\")\n",
        "\n",
        "print(f'Pooled Outputs Shape: {bert_results.pooler_output.shape}')\n",
        "print(f'Pooled Outputs Values: {bert_results.pooler_output[0, :12]}')\n",
        "\n",
        "print(f'Sequence Outputs Shape: {bert_results.last_hidden_state.shape}')\n",
        "print(f'Sequence Outputs Values: {bert_results.last_hidden_state[0, :12, :]}')"
      ],
      "metadata": {
        "id": "su3cOxpEdk4O",
        "outputId": "3cf31bd5-a1f9-4d4d-cb6a-d74a6101c1d0",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "id": "su3cOxpEdk4O",
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Loaded BERT model : <transformers.models.bert.modeling_tf_bert.TFBertModel object at 0x7fa6c4c19950>\n",
            "Pooled Outputs Shape: (1, 768)\n",
            "Pooled Outputs Values: [ 0.06398559 -0.3753235   0.34511548  0.22325964 -0.9989462   0.9971525\n",
            " -0.2679233   0.20474148  0.06282986 -0.99504286 -0.7965103  -0.09152508]\n",
            "Sequence Outputs Shape: (1, 8, 768)\n",
            "Sequence Outputs Values: [[-0.45390198  0.04856572  0.39353645 ...  0.62535435  0.4778933\n",
            "  -0.9104075 ]\n",
            " [ 0.25148723 -0.13441703  0.12725598 ... -0.06474683 -0.371077\n",
            "  -0.7703699 ]\n",
            " [-0.61564076 -0.7248291   0.46139172 ... -0.14295396 -1.0015088\n",
            "   0.38154262]\n",
            " ...\n",
            " [-0.81980765  0.01571992  0.05395365 ... -0.21817678 -0.09767374\n",
            "   0.10209192]\n",
            " [-0.5636111   0.16253881  1.0184888  ...  0.25842923  0.20594317\n",
            "  -0.09941857]\n",
            " [-0.6223204   0.35600746  0.56431425 ... -0.36647758 -0.41368166\n",
            "  -1.0223415 ]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(f\"Keys       : {list(bert_results.keys())}\")"
      ],
      "metadata": {
        "id": "hfCcjDdreOer",
        "outputId": "15ced772-b0c8-4da9-d659-d1f794e2a6cb",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "id": "hfCcjDdreOer",
      "execution_count": 29,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Keys       : ['last_hidden_state', 'pooler_output']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def build_classifier_model(dropout_rate=0.1):\n",
        "\n",
        "    text_input = tf.keras.layers.Input(shape=(), dtype=tf.string, name=\"text\")\n",
        "\n",
        "    def preprocess(text):\n",
        "        return tokenizer(text.numpy(), padding=True, truncation=True, return_tensors=\"tf\")\n",
        "\n",
        "    preprocessing_layer = tf.keras.layers.Lambda(lambda x: tf.py_function(preprocess, [x], tf.float32))(text_input)\n",
        "\n",
        "    encoder = bert_model(preprocessing_layer)\n",
        "\n",
        "    net = encoder.pooler_output\n",
        "    net = tf.keras.layers.Dropout(dropout_rate)(net)\n",
        "\n",
        "    net = tf.keras.layers.Dense(1, activation=\"sigmoid\", name=\"classifier\")(net)\n",
        "\n",
        "    return tf.keras.Model(text_input, net)\n",
        "\n",
        "dropout_rate = 0.15\n",
        "classifier_model = build_classifier_model(dropout_rate)\n",
        "\n",
        "text_test = [\"Bu gerçekten harika bir film!\"]\n",
        "bert_raw_result = classifier_model(tf.constant(text_test))\n",
        "\n",
        "print(bert_raw_result)\n",
        "\n"
      ],
      "metadata": {
        "id": "4G91qfjRenJ7",
        "outputId": "bd8ac849-e5d6-4a8d-f065-de1e7bcc7323",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 460
        }
      },
      "id": "4G91qfjRenJ7",
      "execution_count": 30,
      "outputs": [
        {
          "output_type": "error",
          "ename": "NotImplementedError",
          "evalue": "Exception encountered when calling Lambda.call().\n\n\u001b[1mWe could not automatically infer the shape of the Lambda's output. Please specify the `output_shape` argument for this Lambda layer.\u001b[0m\n\nArguments received by Lambda.call():\n  • args=('<KerasTensor shape=(None,), dtype=string, sparse=False, name=text>',)\n  • kwargs={'mask': 'None'}",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNotImplementedError\u001b[0m                       Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-30-265ee972ea72>\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     18\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     19\u001b[0m \u001b[0mdropout_rate\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m0.15\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 20\u001b[0;31m \u001b[0mclassifier_model\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mbuild_classifier_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdropout_rate\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     21\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     22\u001b[0m \u001b[0mtext_test\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m\"Bu gerçekten harika bir film!\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-30-265ee972ea72>\u001b[0m in \u001b[0;36mbuild_classifier_model\u001b[0;34m(dropout_rate)\u001b[0m\n\u001b[1;32m      6\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mtokenizer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtext\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnumpy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpadding\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtruncation\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreturn_tensors\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"tf\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 8\u001b[0;31m     \u001b[0mpreprocessing_layer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mkeras\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlayers\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mLambda\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;32mlambda\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpy_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpreprocess\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfloat32\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtext_input\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      9\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m     \u001b[0mencoder\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mbert_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpreprocessing_layer\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/keras/src/utils/traceback_utils.py\u001b[0m in \u001b[0;36merror_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    120\u001b[0m             \u001b[0;31m# To get the full stack trace, call:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    121\u001b[0m             \u001b[0;31m# `keras.config.disable_traceback_filtering()`\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 122\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwith_traceback\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfiltered_tb\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    123\u001b[0m         \u001b[0;32mfinally\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    124\u001b[0m             \u001b[0;32mdel\u001b[0m \u001b[0mfiltered_tb\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/keras/src/layers/core/lambda_layer.py\u001b[0m in \u001b[0;36mcompute_output_shape\u001b[0;34m(self, input_shape)\u001b[0m\n\u001b[1;32m     93\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0mtree\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmap_structure\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;32mlambda\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moutput_spec\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     94\u001b[0m             \u001b[0;32mexcept\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 95\u001b[0;31m                 raise NotImplementedError(\n\u001b[0m\u001b[1;32m     96\u001b[0m                     \u001b[0;34m\"We could not automatically infer the shape of \"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     97\u001b[0m                     \u001b[0;34m\"the Lambda's output. Please specify the `output_shape` \"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mNotImplementedError\u001b[0m: Exception encountered when calling Lambda.call().\n\n\u001b[1mWe could not automatically infer the shape of the Lambda's output. Please specify the `output_shape` argument for this Lambda layer.\u001b[0m\n\nArguments received by Lambda.call():\n  • args=('<KerasTensor shape=(None,), dtype=string, sparse=False, name=text>',)\n  • kwargs={'mask': 'None'}"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import sys\n",
        "print(sys.version)  # Detaylı sürüm bilgisi"
      ],
      "metadata": {
        "id": "Ar0Mtil4Lzwr"
      },
      "id": "Ar0Mtil4Lzwr",
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "language_info": {
      "name": "python"
    },
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}